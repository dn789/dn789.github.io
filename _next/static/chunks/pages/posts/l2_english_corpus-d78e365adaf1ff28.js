(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[906],{1494:(e,s,t)=>{(window.__NEXT_P=window.__NEXT_P||[]).push(["/posts/l2_english_corpus",function(){return t(3701)}])},3701:(e,s,t)=>{"use strict";t.r(s),t.d(s,{__toc:()=>d,default:()=>p});var a=t(7876),o=t(301),n=t(655),i=t(5251);t(9085);var r=t(7586);let d=[];function c(e){let s=Object.assign({p:"p",a:"a",code:"code"},(0,r.R)(),e.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(s.p,{children:["This is a ",(0,a.jsx)(s.a,{href:"www.github.com/dn789",children:"tool"})," for automatically generating a corpus of second-language (",(0,a.jsx)(s.code,{children:"L2"}),") English from Reddit posts for a variety of native languages (",(0,a.jsx)(s.code,{children:"L1"}),"s)."]}),"\n",(0,a.jsxs)(s.p,{children:["You'll need a ",(0,a.jsx)(s.code,{children:"Reddit"})," account to access the API (authentication instructions ",(0,a.jsx)(s.a,{href:"https://praw.readthedocs.io/en/stable/getting_started/authentication.html",children:"here"}),")."]}),"\n",(0,a.jsxs)(s.p,{children:["The tool is intialized with a dictionary associating L1s to a list of subreddits with speakers of that language (e.g. if I want a corpus of L2 English by German speakers, I'd add subreddits like ",(0,a.jsx)(s.code,{children:"r/de"})," and ",(0,a.jsx)(s.code,{children:"r/austria"})," to the config). It uses the Reddit API to get comments from users who post/comment in those subreddits. If a user has a sufficient number of comments in the L1, some of their English comments are added to the corpus for that L1."]})]})}let l={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:s}=Object.assign({},(0,r.R)(),e.components);return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(c,{...e})}):c(e)},pageOpts:{filePath:"pages/posts/l2_english_corpus.md",route:"/posts/l2_english_corpus",frontMatter:{title:"L2 English corpus from Reddit",date:"2025/4/18",description:"A corpus of L2 English automatically generated from Reddit comments",tag:"corpus, esl, language acquisition",author:"DN"},timestamp:1747695973e3,pageMap:[{kind:"MdxPage",name:"index",route:"/",frontMatter:{type:"page",title:"Home",date:"2025-05-18T00:00:00.000Z"}},{kind:"MdxPage",name:"papers",route:"/papers",frontMatter:{type:"page",title:"Papers",date:"2025-04-01T00:00:00.000Z"}},{kind:"Folder",name:"posts",route:"/posts",children:[{kind:"MdxPage",name:"corpus_analysis",route:"/posts/corpus_analysis",frontMatter:{title:"Corpus Analysis Tool",date:"2025/5/01",description:"Desktop app for corpus analysis.",tag:"corpus analysis",author:"DN"}},{kind:"MdxPage",name:"index",route:"/posts",frontMatter:{type:"posts",title:"Posts",date:"2021-03-18T00:00:00.000Z"}},{kind:"MdxPage",name:"l2_english_corpus",route:"/posts/l2_english_corpus",frontMatter:{title:"L2 English corpus from Reddit",date:"2025/4/18",description:"A corpus of L2 English automatically generated from Reddit comments",tag:"corpus, esl, language acquisition",author:"DN"}},{kind:"Meta",data:{corpus_analysis:"Corpus Analysis Tool",l2_english_corpus:"L2 English corpus from Reddit",index:"Posts"}}]},{kind:"Meta",data:{index:"Home",papers:"Papers"}}],flexsearch:{codeblocks:!0},title:"L2 English corpus from Reddit",headings:d},pageNextRoute:"/posts/l2_english_corpus",nextraLayout:n.Ay,themeConfig:i.A},p=(0,o.n)(l)},5251:(e,s,t)=>{"use strict";t.d(s,{A:()=>r});var a=t(7876),o=t(4250),n=t.n(o);let i=new Date().getFullYear(),r={footer:(0,a.jsxs)("footer",{className:"jsx-f611ff76f791c99d",children:[(0,a.jsxs)("small",{className:"jsx-f611ff76f791c99d",children:[(0,a.jsx)("time",{className:"jsx-f611ff76f791c99d",children:i})," \xa9 Danny Nassre.",(0,a.jsx)("a",{href:"/feed.xml",className:"jsx-f611ff76f791c99d",children:"RSS"})]}),(0,a.jsx)(n(),{id:"f611ff76f791c99d",children:"footer.jsx-f611ff76f791c99d{margin-top:8rem}a.jsx-f611ff76f791c99d{float:right}"})]})}}},e=>{var s=s=>e(e.s=s);e.O(0,[92,636,593,792],()=>s(1494)),_N_E=e.O()}]);